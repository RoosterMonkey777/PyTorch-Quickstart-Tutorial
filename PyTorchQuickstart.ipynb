{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1661eb02",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f2b81",
   "metadata": {},
   "source": [
    "Runs through the API for common tasks in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a07e22",
   "metadata": {},
   "source": [
    "### Working with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ac1ec",
   "metadata": {},
   "source": [
    "Pytorch has two primitives to work with data:\n",
    "- torch.utils.data.DataLoader\n",
    "- torch.utils.data.Dataset\n",
    "\n",
    "Dataset stores the samples and their corresponding labels. Dataloader wraps an iterable around the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a942cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a8df9",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets. \n",
    "\n",
    "For this tutorial, we will be using a TorchVision dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f15396",
   "metadata": {},
   "source": [
    "The torchvision.datasets module contains Dataset objects for many real-world vision data like CIFAR, COCO, etc (full list: https://pytorch.org/vision/stable/datasets.html). \n",
    "\n",
    "In this tutorial, we use the FashionMNIST dataset. Every TorchVision Dataset includes two arguments: transform and target_transform to modify the samples and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98948f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f5805",
   "metadata": {},
   "source": [
    "Pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. \n",
    "\n",
    "Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b44609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fffa94",
   "metadata": {},
   "source": [
    "N: This represents the number of samples or examples in the batch. In the context of image data, N would be the batch size, which is the number of images processed together during one iteration of training or inference.\n",
    "\n",
    "C: This represents the number of channels in the image. For grayscale images, C would be 1, indicating a single channel. For color images represented in RGB format, C would be 3, representing the three color channels (red, green, blue).\n",
    "\n",
    "H: This represents the height of the image in pixels.\n",
    "\n",
    "W: This represents the width of the image in pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b2daf",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d29625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f4a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b41088",
   "metadata": {},
   "source": [
    "Above code defines a neural network model using the nn.Module class and prints out a summary of the model architecture.\n",
    "\n",
    "1. Define the Neural Network Class (NeuralNetwork):\n",
    "\n",
    "    The NeuralNetwork class is defined, which is a subclass of nn.Module, the base class for all neural network modules in PyTorch.\n",
    "\n",
    "    The __init__ method is called when an instance of the class is created. Inside __init__, the layers of the neural network are defined.\n",
    "    \n",
    "\n",
    "2. Define Layers in the __init__ Method:\n",
    "\n",
    "    - The __init__ method initializes the neural network layers:\n",
    "        - nn.Flatten(): This layer flattens the input tensor into a 1D tensor. It is used to flatten the input images, which are 2D (28x28 pixels), into a 1D tensor (784 pixels).\n",
    "        - nn.Sequential(): This is a container that sequentially applies a list of layers.\n",
    "        - nn.Linear(): This defines fully connected (dense) layers. It takes the size of the input and output as parameters.\n",
    "        - nn.ReLU(): This is the rectified linear unit (ReLU) activation function, applied after each linear layer except the last one.\n",
    "    - The neural network consists of three linear layers with ReLU activation functions between them.\n",
    "    - The first linear layer takes 28x28 input features (the size of the flattened image) and outputs 512 features.\n",
    "    - The second and third linear layers have 512 input features and output 512 features, and 10 features respectively.\n",
    "    - The output of the last linear layer (with 10 output features) represents the logits for each class (in this case, the FashionMNIST dataset has 10 classes).\n",
    "\n",
    "\n",
    "3. Define the forward Method:\n",
    "\n",
    "    - The forward method defines the forward pass of the neural network.\n",
    "    - It takes an input tensor x and passes it through the layers defined in the __init__ method.\n",
    "    - First, the input tensor is flattened using nn.Flatten().\n",
    "    - Then, the flattened tensor is passed through the sequential layer defined in the __init__ method.\n",
    "    - The output of the last linear layer (logits) is returned.\n",
    "    \n",
    "    \n",
    "4. Instantiate the Model and Move to Device (model = NeuralNetwork().to(device)):\n",
    "\n",
    "    - An instance of the NeuralNetwork class is created.\n",
    "    - It is then moved to the device specified earlier (CPU, GPU, or MPS) using the to method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68cc7d",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
